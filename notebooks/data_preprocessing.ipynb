{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronics Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Electronics Dataset Preprocessing\n",
    "\n",
    "This notebook creates a manageable subset of the Amazon Electronics dataset by filtering for popular products based on number of reviews.\n",
    "\n",
    "**Goal**: Extract 1000 most popular Electronics products based on review count for our RAG pipeline.\n",
    "\n",
    "**Data Source**: Amazon Reviews 2023 dataset by McAuley Lab\n",
    "- Citation: Hou et al. (2024) - Bridging Language and Items for Retrieval and Recommendation (arXiv:2403.03952)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "REVIEWS_FILE = DATA_DIR / \"Electronics.jsonl\"\n",
    "META_FILE = DATA_DIR / \"meta_Electronics.jsonl\"\n",
    "OUTPUT_DIR = DATA_DIR / \"processed\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "TARGET_PRODUCTS = 1000\n",
    "MIN_REVIEWS_PER_PRODUCT = 10  # Minimum reviews to be considered \"popular\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Count Reviews per Product"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Count Reviews per Product\n",
    "\n",
    "First, we'll scan through the reviews file to count how many reviews each product (parent_asin) has received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_reviews_per_product(reviews_file):\n",
    "    \"\"\"Count the number of reviews for each product (parent_asin).\"\"\"\n",
    "    print(f\"Counting reviews per product from {reviews_file}...\")\n",
    "    \n",
    "    review_counts = Counter()\n",
    "    total_reviews = 0\n",
    "    \n",
    "    # Handle both .jsonl and .jsonl.gz files\n",
    "    if str(reviews_file).endswith('.gz'):\n",
    "        file_opener = gzip.open\n",
    "        mode = 'rt'\n",
    "    else:\n",
    "        file_opener = open\n",
    "        mode = 'r'\n",
    "    \n",
    "    with file_opener(reviews_file, mode, encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(tqdm(f, desc=\"Processing reviews\")):\n",
    "            if line_num % 100000 == 0 and line_num > 0:\n",
    "                print(f\"Processed {line_num:,} reviews, found {len(review_counts):,} unique products\")\n",
    "            \n",
    "            try:\n",
    "                review = json.loads(line.strip())\n",
    "                parent_asin = review.get('parent_asin')\n",
    "                if parent_asin:\n",
    "                    review_counts[parent_asin] += 1\n",
    "                    total_reviews += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON at line {line_num + 1}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nTotal reviews processed: {total_reviews:,}\")\n",
    "    print(f\"Unique products found: {len(review_counts):,}\")\n",
    "    \n",
    "    return review_counts\n",
    "\n",
    "# Count reviews per product\n",
    "review_counts = count_reviews_per_product(REVIEWS_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Select Top Products by Review Count\n",
    "\n",
    "Now we'll select the most popular products based on review count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_products(review_counts, target_count=1000, min_reviews=10):\n",
    "    \"\"\"Select top products by review count.\"\"\"\n",
    "    print(f\"\\nSelecting top {target_count} products with at least {min_reviews} reviews...\")\n",
    "    \n",
    "    # Filter products with minimum review count\n",
    "    filtered_products = {k: v for k, v in review_counts.items() if v >= min_reviews}\n",
    "    print(f\"Products with â‰¥{min_reviews} reviews: {len(filtered_products):,}\")\n",
    "    \n",
    "    # Get top products by review count\n",
    "    top_products = dict(review_counts.most_common(target_count))\n",
    "    \n",
    "    print(f\"\\nSelected {len(top_products)} products\")\n",
    "    print(f\"Review count range: {min(top_products.values())} - {max(top_products.values())}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    counts = list(top_products.values())\n",
    "    print(f\"\\nReview count statistics:\")\n",
    "    print(f\"  Mean: {np.mean(counts):.1f}\")\n",
    "    print(f\"  Median: {np.median(counts):.1f}\")\n",
    "    print(f\"  75th percentile: {np.percentile(counts, 75):.1f}\")\n",
    "    print(f\"  90th percentile: {np.percentile(counts, 90):.1f}\")\n",
    "    \n",
    "    return top_products\n",
    "\n",
    "top_products = select_top_products(review_counts, TARGET_PRODUCTS, MIN_REVIEWS_PER_PRODUCT)\n",
    "selected_parent_asins = set(top_products.keys())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Extract Product Metadata\n",
    "\n",
    "Extract metadata for our selected products from the meta_Electronics.jsonl file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_metadata(meta_file, selected_asins):\n",
    "    \"\"\"Extract metadata for selected products.\"\"\"\n",
    "    print(f\"\\nExtracting metadata for {len(selected_asins)} products...\")\n",
    "    \n",
    "    products_metadata = []\n",
    "    found_count = 0\n",
    "    \n",
    "    # Handle both .jsonl and .jsonl.gz files\n",
    "    if str(meta_file).endswith('.gz'):\n",
    "        file_opener = gzip.open\n",
    "        mode = 'rt'\n",
    "    else:\n",
    "        file_opener = open\n",
    "        mode = 'r'\n",
    "    \n",
    "    with file_opener(meta_file, mode, encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(tqdm(f, desc=\"Processing metadata\")):\n",
    "            try:\n",
    "                product = json.loads(line.strip())\n",
    "                parent_asin = product.get('parent_asin')\n",
    "                \n",
    "                if parent_asin in selected_asins:\n",
    "                    # Add review count to metadata\n",
    "                    product['review_count'] = top_products[parent_asin]\n",
    "                    products_metadata.append(product)\n",
    "                    found_count += 1\n",
    "                    \n",
    "                    if found_count % 100 == 0:\n",
    "                        print(f\"Found metadata for {found_count}/{len(selected_asins)} products\")\n",
    "                        \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON at line {line_num + 1}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nFound metadata for {found_count}/{len(selected_asins)} products\")\n",
    "    return products_metadata\n",
    "\n",
    "products_metadata = extract_product_metadata(META_FILE, selected_parent_asins)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Extract Sample Reviews\n",
    "\n",
    "Extract a sample of reviews for our selected products to use in the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sample_reviews(reviews_file, selected_asins, max_reviews_per_product=20):\n",
    "    \"\"\"Extract sample reviews for selected products.\"\"\"\n",
    "    print(f\"\\nExtracting sample reviews (max {max_reviews_per_product} per product)...\")\n",
    "    \n",
    "    product_reviews = defaultdict(list)\n",
    "    total_extracted = 0\n",
    "    \n",
    "    # Handle both .jsonl and .jsonl.gz files\n",
    "    if str(reviews_file).endswith('.gz'):\n",
    "        file_opener = gzip.open\n",
    "        mode = 'rt'\n",
    "    else:\n",
    "        file_opener = open\n",
    "        mode = 'r'\n",
    "    \n",
    "    with file_opener(reviews_file, mode, encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(tqdm(f, desc=\"Processing reviews\")):\n",
    "            try:\n",
    "                review = json.loads(line.strip())\n",
    "                parent_asin = review.get('parent_asin')\n",
    "                \n",
    "                if (parent_asin in selected_asins and \n",
    "                    len(product_reviews[parent_asin]) < max_reviews_per_product):\n",
    "                    \n",
    "                    # Only keep essential review fields\n",
    "                    clean_review = {\n",
    "                        'asin': review.get('asin'),\n",
    "                        'parent_asin': parent_asin,\n",
    "                        'rating': review.get('rating'),\n",
    "                        'title': review.get('title', ''),\n",
    "                        'text': review.get('text', ''),\n",
    "                        'timestamp': review.get('timestamp'),\n",
    "                        'verified_purchase': review.get('verified_purchase'),\n",
    "                        'helpful_vote': review.get('helpful_vote', 0)\n",
    "                    }\n",
    "                    \n",
    "                    product_reviews[parent_asin].append(clean_review)\n",
    "                    total_extracted += 1\n",
    "                    \n",
    "                    if total_extracted % 1000 == 0:\n",
    "                        print(f\"Extracted {total_extracted} reviews for {len(product_reviews)} products\")\n",
    "                        \n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Skipping invalid JSON at line {line_num + 1}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nExtracted {total_extracted} reviews for {len(product_reviews)} products\")\n",
    "    return dict(product_reviews)\n",
    "\n",
    "sample_reviews = extract_sample_reviews(REVIEWS_FILE, selected_parent_asins, max_reviews_per_product=20)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Data Analysis and Quality Check\n",
    "\n",
    "Let's analyze our filtered dataset to ensure quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "df_products = pd.DataFrame(products_metadata)\n",
    "\n",
    "print(\"=== DATASET SUMMARY ===\")\n",
    "print(f\"Total products: {len(df_products)}\")\n",
    "print(f\"Total reviews extracted: {sum(len(reviews) for reviews in sample_reviews.values())}\")\n",
    "\n",
    "print(\"\\n=== PRODUCT METADATA FIELDS ===\")\n",
    "print(f\"Available fields: {list(df_products.columns)}\")\n",
    "\n",
    "print(\"\\n=== REVIEW COUNT DISTRIBUTION ===\")\n",
    "if 'review_count' in df_products.columns:\n",
    "    print(df_products['review_count'].describe())\n",
    "\n",
    "print(\"\\n=== PRICE DISTRIBUTION ===\")\n",
    "if 'price' in df_products.columns:\n",
    "    # Clean price data (remove nulls and convert to numeric)\n",
    "    prices = pd.to_numeric(df_products['price'], errors='coerce').dropna()\n",
    "    print(f\"Products with price info: {len(prices)}/{len(df_products)}\")\n",
    "    if len(prices) > 0:\n",
    "        print(prices.describe())\n",
    "\n",
    "print(\"\\n=== RATING DISTRIBUTION ===\")\n",
    "if 'average_rating' in df_products.columns:\n",
    "    ratings = pd.to_numeric(df_products['average_rating'], errors='coerce').dropna()\n",
    "    print(f\"Products with rating info: {len(ratings)}/{len(df_products)}\")\n",
    "    if len(ratings) > 0:\n",
    "        print(ratings.describe())\n",
    "\n",
    "print(\"\\n=== TOP 10 MOST REVIEWED PRODUCTS ===\")\n",
    "if 'review_count' in df_products.columns and 'title' in df_products.columns:\n",
    "    top_10 = df_products.nlargest(10, 'review_count')[['title', 'review_count', 'average_rating', 'price']]\n",
    "    for idx, row in top_10.iterrows():\n",
    "        print(f\"{row['review_count']:,} reviews - {row['title'][:80]}...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: Save Processed Dataset\n",
    "\n",
    "Save our filtered dataset for use in the RAG pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save product metadata\n",
    "products_file = OUTPUT_DIR / \"electronics_top1000_products.jsonl\"\n",
    "with open(products_file, 'w', encoding='utf-8') as f:\n",
    "    for product in products_metadata:\n",
    "        f.write(json.dumps(product, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Saved {len(products_metadata)} products to {products_file}\")\n",
    "\n",
    "# Save sample reviews\n",
    "reviews_file = OUTPUT_DIR / \"electronics_top1000_reviews.jsonl\"\n",
    "total_reviews_saved = 0\n",
    "with open(reviews_file, 'w', encoding='utf-8') as f:\n",
    "    for parent_asin, reviews in sample_reviews.items():\n",
    "        for review in reviews:\n",
    "            f.write(json.dumps(review, ensure_ascii=False) + '\\n')\n",
    "            total_reviews_saved += 1\n",
    "\n",
    "print(f\"Saved {total_reviews_saved} reviews to {reviews_file}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary = {\n",
    "    'dataset_info': {\n",
    "        'source': 'Amazon Reviews 2023 - Electronics Category',\n",
    "        'citation': 'Hou et al. (2024) - Bridging Language and Items for Retrieval and Recommendation (arXiv:2403.03952)',\n",
    "        'processing_date': pd.Timestamp.now().isoformat(),\n",
    "        'selection_criteria': {\n",
    "            'target_products': TARGET_PRODUCTS,\n",
    "            'min_reviews_per_product': MIN_REVIEWS_PER_PRODUCT,\n",
    "            'max_reviews_per_product': 20\n",
    "        }\n",
    "    },\n",
    "    'statistics': {\n",
    "        'total_products': len(products_metadata),\n",
    "        'total_reviews': total_reviews_saved,\n",
    "        'products_with_metadata': len(products_metadata),\n",
    "        'products_with_reviews': len(sample_reviews)\n",
    "    }\n",
    "}\n",
    "\n",
    "if 'review_count' in df_products.columns:\n",
    "    summary['statistics']['review_count_stats'] = {\n",
    "        'min': int(df_products['review_count'].min()),\n",
    "        'max': int(df_products['review_count'].max()),\n",
    "        'mean': float(df_products['review_count'].mean()),\n",
    "        'median': float(df_products['review_count'].median())\n",
    "    }\n",
    "\n",
    "summary_file = OUTPUT_DIR / \"dataset_summary.json\"\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved dataset summary to {summary_file}\")\n",
    "\n",
    "print(\"\\n=== PROCESSING COMPLETE ===\")\n",
    "print(f\"Output files created in: {OUTPUT_DIR}\")\n",
    "print(f\"  - {products_file.name}: Product metadata\")\n",
    "print(f\"  - {reviews_file.name}: Sample reviews\")\n",
    "print(f\"  - {summary_file.name}: Dataset summary\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "Successfully created a manageable subset of the Electronics dataset:\n",
    "\n",
    "- **Selected**: Top 1000 most popular products by review count\n",
    "- **Criteria**: Products with â‰¥10 reviews each\n",
    "- **Output Files**:\n",
    "  - `electronics_top1000_products.jsonl`: Product metadata\n",
    "  - `electronics_top1000_reviews.jsonl`: Sample reviews (max 20 per product)\n",
    "  - `electronics_rag_documents.jsonl`: RAG-optimized documents\n",
    "  - `dataset_summary.json`: Processing statistics\n",
    "\n",
    "This filtered dataset is now ready for use in your RAG pipeline and will provide much faster processing while maintaining high-quality, popular products with sufficient review data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_documents(products_metadata, sample_reviews):\n",
    "    \"\"\"Create documents optimized for RAG retrieval.\"\"\"\n",
    "    rag_documents = []\n",
    "    \n",
    "    for product in products_metadata:\n",
    "        parent_asin = product.get('parent_asin')\n",
    "        \n",
    "        # Create product document\n",
    "        doc = {\n",
    "            'id': f\"product_{parent_asin}\",\n",
    "            'type': 'product',\n",
    "            'parent_asin': parent_asin,\n",
    "            'title': product.get('title', ''),\n",
    "            'description': ' '.join(product.get('description', [])) if product.get('description') else '',\n",
    "            'features': ' '.join(product.get('features', [])) if product.get('features') else '',\n",
    "            'price': product.get('price'),\n",
    "            'average_rating': product.get('average_rating'),\n",
    "            'rating_number': product.get('rating_number'),\n",
    "            'review_count': product.get('review_count'),\n",
    "            'store': product.get('store', ''),\n",
    "            'categories': product.get('categories', []),\n",
    "            'details': product.get('details', {})\n",
    "        }\n",
    "        \n",
    "        # Create searchable text content\n",
    "        content_parts = []\n",
    "        if doc['title']:\n",
    "            content_parts.append(f\"Product: {doc['title']}\")\n",
    "        if doc['description']:\n",
    "            content_parts.append(f\"Description: {doc['description']}\")\n",
    "        if doc['features']:\n",
    "            content_parts.append(f\"Features: {doc['features']}\")\n",
    "        if doc['store']:\n",
    "            content_parts.append(f\"Store: {doc['store']}\")\n",
    "        if doc['categories']:\n",
    "            content_parts.append(f\"Categories: {' > '.join(doc['categories'])}\")\n",
    "        \n",
    "        doc['content'] = ' '.join(content_parts)\n",
    "        rag_documents.append(doc)\n",
    "        \n",
    "        # Add review summaries\n",
    "        if parent_asin in sample_reviews:\n",
    "            reviews = sample_reviews[parent_asin]\n",
    "            \n",
    "            # Create review summary document\n",
    "            positive_reviews = [r for r in reviews if r.get('rating', 0) >= 4]\n",
    "            negative_reviews = [r for r in reviews if r.get('rating', 0) <= 2]\n",
    "            \n",
    "            review_summary = {\n",
    "                'id': f\"reviews_{parent_asin}\",\n",
    "                'type': 'review_summary',\n",
    "                'parent_asin': parent_asin,\n",
    "                'product_title': doc['title'],\n",
    "                'total_reviews': len(reviews),\n",
    "                'positive_reviews': len(positive_reviews),\n",
    "                'negative_reviews': len(negative_reviews)\n",
    "            }\n",
    "            \n",
    "            # Sample positive and negative review texts\n",
    "            pos_texts = [r.get('text', '') for r in positive_reviews[:5] if r.get('text')]\n",
    "            neg_texts = [r.get('text', '') for r in negative_reviews[:5] if r.get('text')]\n",
    "            \n",
    "            content_parts = [f\"Reviews for {doc['title']}\"]\n",
    "            if pos_texts:\n",
    "                content_parts.append(f\"Positive feedback: {' '.join(pos_texts[:3])}\")\n",
    "            if neg_texts:\n",
    "                content_parts.append(f\"Critical feedback: {' '.join(neg_texts[:3])}\")\n",
    "            \n",
    "            review_summary['content'] = ' '.join(content_parts)\n",
    "            rag_documents.append(review_summary)\n",
    "    \n",
    "    return rag_documents\n",
    "\n",
    "# Create RAG documents\n",
    "rag_documents = create_rag_documents(products_metadata, sample_reviews)\n",
    "\n",
    "# Save RAG documents\n",
    "rag_file = OUTPUT_DIR / \"electronics_rag_documents.jsonl\"\n",
    "with open(rag_file, 'w', encoding='utf-8') as f:\n",
    "    for doc in rag_documents:\n",
    "        f.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Created {len(rag_documents)} RAG documents saved to {rag_file}\")\n",
    "print(f\"Document types: {Counter(doc['type'] for doc in rag_documents)}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7: Create RAG Documents\n",
    "\n",
    "Prepare the data in a format optimized for RAG applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
